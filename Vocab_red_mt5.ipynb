{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15925e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /data/yash/miniconda3/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2022-05-22 13:09:34--  https://raw.githubusercontent.com/google/sentencepiece/master/src/sentencepiece_model.proto\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12872 (13K) [text/plain]\n",
      "Saving to: ‘sentencepiece_model.proto.1’\n",
      "\n",
      "sentencepiece_model 100%[===================>]  12.57K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2022-05-22 13:09:35 (3.77 MB/s) - ‘sentencepiece_model.proto.1’ saved [12872/12872]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/google/sentencepiece/master/src/sentencepiece_model.proto\n",
    "! protoc --python_out=. sentencepiece_model.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73038926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('google/mt5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d759a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32981729710484153\n",
      "0.32981729710484153\n"
     ]
    }
   ],
   "source": [
    "def msize(m):\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "print(msize(model.shared) / msize(model))   # 0.3298\n",
    "print(msize(model.lm_head) / msize(model))  # 0.3298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f1fcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ffc81b0f7946e48bf6e1fc21db1245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8466307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67652 0.270499800079968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm, trange\n",
    "data =[]\n",
    "with open('en-hi/train.hi','r') as f:\n",
    "    data = [s.strip('\\n').replace('  ', ' ') for s in f.readlines()]\n",
    "cnt_ru = Counter()\n",
    "for text in tqdm(data):\n",
    "    cnt_ru.update(tokenizer.encode(text))\n",
    "print(len(cnt_ru), len(cnt_ru)/tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5219138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161321f07283491fac145015459ad563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8466307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82029 0.32798480607756897\n"
     ]
    }
   ],
   "source": [
    "data =[]\n",
    "with open('en-hi/train.en','r') as f:\n",
    "    data = [s.strip('\\n').replace('  ', ' ') for s in f.readlines()]\n",
    "cnt_en = Counter()\n",
    "for text in tqdm(data):\n",
    "    cnt_en.update(tokenizer.encode(text))\n",
    "print(len(cnt_en), len(cnt_en)/tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9b40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = len(set(cnt_ru.keys()).intersection(set(cnt_en.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28973280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54771 0.8095991249334831\n"
     ]
    }
   ],
   "source": [
    "print(common, common / len(cnt_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbfeaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru\n",
      "10000 0.9984905625596253\n",
      "20000 0.9994138378817895\n",
      "30000 0.9997237355070604\n",
      "en\n",
      "10000 0.9564890253740371\n",
      "20000 0.9859295854825768\n",
      "30000 0.9944200294217131\n"
     ]
    }
   ],
   "source": [
    "print('ru')\n",
    "for top in 10_000, 20_000, 30_000:\n",
    "    print(top, sum(v for k, v in cnt_ru.most_common(top)) / sum(cnt_ru.values()))\n",
    "print('en')\n",
    "for top in 10_000, 20_000, 30_000:\n",
    "    print(top, sum(v for k, v in cnt_en.most_common(top)) / sum(cnt_en.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18b3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_voc = tokenizer.get_vocab()\n",
    "old_inv_voc = {v: k for k, v in old_voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23319b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37744cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd74dd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51511\n"
     ]
    }
   ],
   "source": [
    "new_tokens = set(range(1000))\n",
    "for i, (k, v) in enumerate(cnt_en.most_common(35_000)):\n",
    "    if k not in new_tokens:\n",
    "        new_tokens.add(k)\n",
    "for i, (k, v) in enumerate(cnt_ru.most_common(40_000)):\n",
    "    if len(new_tokens) == 80_900:\n",
    "        print(i, 'Hindi tokens are included')\n",
    "        break\n",
    "    if k not in new_tokens:\n",
    "        new_tokens.add(k)\n",
    "for t in range(tokenizer.vocab_size - 100, tokenizer.vocab_size):\n",
    "    new_tokens.add(t)\n",
    "print(len(new_tokens))\n",
    "kept_ids = sorted(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e80192",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = len(kept_ids)\n",
    "new_emb = torch.nn.Embedding(new_size, model.shared.embedding_dim)\n",
    "new_head = torch.nn.Linear(in_features=model.lm_head.in_features, out_features=new_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35318d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_id, old_id in enumerate(kept_ids):\n",
    "    new_emb.weight.data[new_id] = model.shared.weight.data[old_id]\n",
    "    new_head.weight.data[new_id] = model.lm_head.weight.data[old_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8b29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.shared.weight = new_emb.weight\n",
    "model.lm_head.weight = new_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94125af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loaded model has pieces: 250100\n",
      "the new pieces: 51511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a110f8e16bc4fb8bd91d1853267dd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51511\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece_model_pb2 as spmp\n",
    "smp = tokenizer.sp_model.serialized_model_proto()\n",
    "m = spmp.ModelProto()\n",
    "m.ParseFromString(smp)\n",
    "\n",
    "print('the loaded model has pieces:', len(m.pieces))\n",
    "new_pieces = [m.pieces[idx] for idx in kept_ids]\n",
    "print('the new pieces:', len(new_pieces))\n",
    "\n",
    "# replace the content of the first 30K pieces\n",
    "for i, p in enumerate(new_pieces):\n",
    "    m.pieces[i].piece = p.piece\n",
    "    m.pieces[i].score = p.score\n",
    "    m.pieces[i].type = p.type\n",
    "\n",
    "# drop the remaining pieces\n",
    "n = len(new_pieces)\n",
    "for i in trange(len(m.pieces) - n):\n",
    "    m.pieces.pop(len(m.pieces) - 1)\n",
    "\n",
    "print(len(m.pieces))\n",
    "with open('new_sp.model', 'wb') as f:\n",
    "    f.write(m.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0430c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = T5Tokenizer('new_sp.model', extra_ids=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2d902e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"cointegrated/hit5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"T5Tokenizer\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51511\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.__dict__['vocab_size'] = new_size\n",
    "model.config.__dict__['_name_or_path'] = 'cointegrated/hit5-base'\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a1d244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.save_pretrained('hit5-base')\n",
    "model.save_pretrained('hit5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "364851e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1G\r\n",
      "4.0K drwxrwxr-x  2 yash yash    4.0K May 22 14:05 .\r\n",
      "4.0K drwxrwxr-x 31 yash prospar 4.0K May 22 14:15 ..\r\n",
      "4.0K -rw-rw-r--  1 yash yash     748 May 22 14:05 config.json\r\n",
      "1.1G -rw-rw-r--  1 yash yash    1.1G May 22 14:05 pytorch_model.bin\r\n",
      "4.0K -rw-rw-r--  1 yash yash      65 May 22 14:05 special_tokens_map.json\r\n",
      "1.1M -rw-rw-r--  1 yash yash    1.1M May 22 14:05 spiece.model\r\n",
      "4.0K -rw-rw-r--  1 yash yash     173 May 22 14:05 tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls hin5-base -alsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d10cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = T5ForConditionalGeneration.from_pretrained('hit5-base')\n",
    "tokenizer1 = T5Tokenizer.from_pretrained('hit5-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ba795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.t5 import T5Model, T5Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8201e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d35f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42afbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = T5Args()\n",
    "model_args.max_seq_length = 64\n",
    "model_args.train_batch_size = 8\n",
    "model_args.eval_batch_size = 8\n",
    "model_args.num_train_epochs = 4\n",
    "model_args.evaluate_during_training_steps = 30000\n",
    "model_args.use_multiprocessing = False\n",
    "model_args.fp16 = False\n",
    "model_args.save_steps = -1\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.no_cache = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.preprocess_inputs = False\n",
    "model_args.num_beams = 3\n",
    "model_args.num_return_sequences = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd9e1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type t5 to instantiate a model of type mt5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model = T5Model('mt5','hit5-base', args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f6d28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5Config {\n",
       "  \"_name_or_path\": \"hit5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"mt5\",\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"T5Tokenizer\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51511\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1146a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
